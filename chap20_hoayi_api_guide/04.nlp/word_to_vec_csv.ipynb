{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec 란?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 정보 Setting \n",
    "서버에 접속하기 위한 주소, 네트워크 ID, 버전 정보를 Global 변수로 정의한다. <br>\n",
    "새로운 형태의 네트워크를 정의하기 위해서는 네트워크 ID 혹은 버전을 변경하여 새롭게 Graph 를 정의해야 한다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json, os\n",
    "\n",
    "url = \"{0}:{1}\".format(os.environ['HOSTNAME'] , \"8000\")\n",
    "nn_id = \"nn05\"\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network 정의\n",
    "nn_id : Neural Network ID<br>\n",
    "biz_cate : Business 대분류<br>\n",
    "biz_sub_cate : Business 소분류<br>\n",
    "nn_title : Neural Network Title<br>\n",
    "nn_desc : Neural Network Description<br>\n",
    "use_flag : 사용여부<br> \n",
    "dir : 문제유형<br>\n",
    "config : Custom 여부 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : nn05\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/common/target/nninfo/nnid/' + nn_id + '/',\n",
    "                     json={\n",
    "                         \"biz_cate\": \"MES\",\n",
    "                         \"biz_sub_cate\": \"M60\",\n",
    "                         \"nn_title\" : \"test\",\n",
    "                         \"nn_desc\": \"test desc\",\n",
    "                         \"use_flag\" : \"Y\",\n",
    "                         \"dir\": \"purpose?\",\n",
    "                         \"config\": \"N\"\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : ['1 file upload success']\n"
     ]
    }
   ],
   "source": [
    "return_dict = {}\n",
    "return_dict['test'] = open('../../data/seq2seq_mansearch_2.csv', 'rb')\n",
    "\n",
    "resp = requests.post('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/frame/prg/source/nnid/'+nn_id+'/ver/1/node/data_node/',\n",
    "                     files = return_dict)\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Flow Version 정의\n",
    "nn_def_list_info_nn_id :<br>\n",
    "nn_wf_ver_info : Work Flow Version Description<br>\n",
    "condition :<br>\n",
    "active_flag : 사용여부\n",
    "master_nn_ver_wflist_info insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : nn05\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/common/target/nninfo/nnid/' + nn_id + '/version/',\n",
    "                     json={\n",
    "                         \"nn_def_list_info_nn_id\": \"\",\n",
    "                         \"nn_wf_ver_info\": \"test version info\",\n",
    "                         \"condition\": \"1\",\n",
    "                         \"active_flag\": \"Y\"\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Flow Node  Initialize\n",
    "type : Neural Network Type<br>\n",
    "1. Data Node<br>\n",
    "2. Neural Network Node<br>\n",
    "3. Evaluation Node<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : word2vec_frame\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/wf/target/init/mode/simple/'+ nn_id + '/wfver/1/',\n",
    "                     json={\n",
    "                         \"type\": \"word2vec_frame\"\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Node Config\n",
    "type : Image Source Type<br>\n",
    "labels : Classfication Labels<br>\n",
    "source_path : Image Source Path<br>\n",
    "preprocess : Image Preprocess Config<br>\n",
    "store_path : Image Store Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : {'source_type': 'local', 'source_sql': 'all', 'multi_node_flag': None, 'source_server': 'local', 'source_path': '/hoya_src_root/nn05/1/data_node', 'type': 'csv', 'max_sentence_len': 0, 'source_parse_type': 'frame'}\n",
      "evaluation result : null\n",
      "evaluation result : /hoya_str_root/nn05/1/data_node\n"
     ]
    }
   ],
   "source": [
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/frame/prg/source/nnid/'+ nn_id + '/ver/1/node/data_node/',\n",
    "                     json={\n",
    "                         \"type\": \"csv\",\n",
    "                         \"source_server\": \"local\",\n",
    "                         \"source_sql\": \"all\",\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "#\n",
    "#update preprocess\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/raw/prg/pre/nnid/'+ nn_id + '/ver/1/node/data_node/',\n",
    "                      json={\n",
    "                          \"preprocess\":  \"null\",\n",
    "                      })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "#\n",
    " # update store_path\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/frame/prg/store/nnid/'+ nn_id + '/ver/1/node/data_node/',\n",
    "                      json={\n",
    "                          \"store_path\": \"test\"\n",
    "                      })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : {'col_list': ['decode', 'encode'], 'max_sentence_len': 30, 'preprocess': 'mecab'}\n"
     ]
    }
   ],
   "source": [
    "# merge data sets to one\n",
    "resp = requests.post('http://' + url + '/api/v1/type/wf/state/pre/detail/feed/src/frame/net/word2vec/nnid/'+ nn_id + '/ver/1/node/pre_feed_fr2wv_train/',\n",
    "                     json={\n",
    "                         \"col_list\" : [\"decode\",\"encode\"],\n",
    "                         \"max_sentence_len\": 30,\n",
    "                         \"preprocess\": \"mecab\",\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Graph Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : ['1 file upload success']\n",
      "evaluation result : {'source_type': 'local', 'source_sql': 'all', 'multi_node_flag': None, 'source_server': 'local', 'source_path': '/hoya_src_root/nn05/1/test_data_node', 'type': 'csv', 'max_sentence_len': 0, 'source_parse_type': 'raw'}\n",
      "evaluation result : null\n",
      "evaluation result : /hoya_str_root/nn05/1/test_data_node\n",
      "evaluation result : {'col_list': ['encode', 'decode'], 'max_sentence_len': 30, 'preprocess': 'mecab'}\n"
     ]
    }
   ],
   "source": [
    "return_dict = {}\n",
    "return_dict['test'] = open('../../data/seq2seq_mansearch_2.csv', 'rb')\n",
    "\n",
    "resp = requests.post('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/raw/prg/source/nnid/'+ nn_id + '/ver/1/node/test_data_node/',\n",
    "                     files = return_dict)\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/raw/prg/source/nnid/'+ nn_id + '/ver/1/node/test_data_node/',\n",
    "                     json={\n",
    "                         \"type\": \"csv\",\n",
    "                         \"source_server\": \"local\",\n",
    "                         \"source_sql\": \"all\",\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "\n",
    "#update preprocess\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/raw/prg/pre/nnid/'+ nn_id + '/ver/1/node/test_data_node/',\n",
    "                    json={\"preprocess\" : \"null\"})\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "\n",
    " # update store_path\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/framedata/src/local/form/raw/prg/store/nnid/'+ nn_id + '/ver/1/node/test_data_node/')\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n",
    "\n",
    "\n",
    "# merge data sets to one\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/pre/detail/feed/src/frame/net/word2vec/nnid/'+ nn_id + '/ver/1/node/pre_feed_fr2wv_test/',\n",
    "                     json={\n",
    "                         \"col_list\" : [\"encode\",\"decode\"],\n",
    "                         \"max_sentence_len\": 30,\n",
    "                         \"preprocess\": \"mecab\",\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Node Config\n",
    "model_path : Model Save Path<br>\n",
    "window_size : 문장 내의 현재 단어와 예측 단어 사이의 최대 거리.<br>\n",
    "vector_size : 백터사이즈.<br>\n",
    "batch_size : Batch Size (Vocabary Distance)<br>\n",
    "iter : Trainning Iteration<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : {'min_count': 1, 'model_path': '/hoya_model_root/nn05/1/netconf_node', 'batch_size': 100, 'iter': 5, 'window_size': 3, 'vector_size': 500}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# update source_info\n",
    "# set netconf_node in NN_WF_NODE_INFO\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/netconf/detail/w2v/nnid/' + nn_id + '/ver/1/node/netconf_node/',\n",
    "                     json={\n",
    "                        \"window_size\" : 3,\n",
    "                        \"vector_size\" : 500,\n",
    "                        \"batch_size\" : 100,\n",
    "                        \"iter\" : 5,\n",
    "                        \"min_count\" : 1\n",
    "                     })\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Node Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : {'type': 'w2v'}\n"
     ]
    }
   ],
   "source": [
    "node_name = 'eval_node'\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/eval/nnid/'+nn_id+'/ver/1/node/'+node_name+'/',\n",
    "                    json={\n",
    "                        \"type\": \"w2v\",\n",
    "                    })\n",
    "\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : {'status': '404', 'result': \"eval() got an unexpected keyword argument 'data'\"}\n"
     ]
    }
   ],
   "source": [
    "# Run All Workflow\n",
    "resp = requests.post('http://' + url + '/api/v1/type/runmanager/state/train/nnid/'+nn_id+'/ver/1/')\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "type :  sim\n",
    "val_1 : [철강,권오준,연구원,포스코]\n",
    "\n",
    "\n",
    "포스코-적자\n",
    "철강-포스코\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation result : [[['보내/VV', 0.9939898252487183], ['줘/EC+VV+EC', 0.9823461771011353], ['문자/NNG', 0.977975606918335], ['오/VV', 0.9747863411903381], ['빨리/MAG', 0.9656846523284912]]]\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/service/state/predict/type/w2v/nnid/' + nn_id + '/ver/active/',\n",
    "                     json={\n",
    "                         \"type\": \"sim\",\n",
    "                         \"val_1\":[\"메일\"],\n",
    "                         \"val_2\":[\"\"]\n",
    "                          }\n",
    "                    )\n",
    "data = json.loads(resp.json())\n",
    "print(\"evaluation result : {0}\".format(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
