{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent 와 NER 모델을 만들기 위한 Data의 구성 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "train_data_order = ['판교에 오늘 피자 주문해줘']\n",
    "train_data_reserve = ['오늘 날짜에 호텔 예약 해줄레']\n",
    "train_data_info = ['오늘 날짜에 판교 여행 정보 알려줘']\n",
    "\n",
    "dict_entity = {\n",
    "    'date' : ['오늘','내일','모래'],\n",
    "    'loc' : ['판교','야탑','서현'],\n",
    "    'menu' : ['피자','햄버거','치킨'],\n",
    "    'hotel' : ['호텔','여관','민박'],\n",
    "    'travel' : ['여행','놀러갈','구경']\n",
    "}\n",
    "\n",
    "length = 1\n",
    "for key in list(dict_entity.keys()):\n",
    "    length = length * len(dict_entity[key])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector 구성 (a~z / 한글)\n",
    " - 일반적으로 처리단위가 작아질수록 미등록어에서 자유롭고 작은 vector 차원을 유지할 수 있지만\n",
    " - 문장의 길이가 길어지고, 학습이 어려워지는 문제가 있기에 적절한 embedding을 찾아야하는데 \n",
    " - 이부분은 Biz Domain 별 차이가 있음 복잡도나 표현 가능성등을 적절한 균형에서 찾아야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "           \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('판교', 'NNG'), ('에', 'JKB'), ('오늘', 'MAG'), ('피자', 'NNG'), ('주문', 'NNG'), ('해', 'XSV+EC'), ('줘', 'VX+EC')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab('/usr/local/lib/mecab/dic/mecab-ko-dic')\n",
    "morpphed_text = mecab.pos(train_data_order[0])\n",
    "print(morpphed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (명사만 도출)\n",
    "\n",
    "Feature Engineering으로 Intent와 NER의 정확도를 높임)\n",
    " - 일반명사(NNG) [메뉴]\n",
    " - 고유명사(NNP) [지역]\n",
    " - 영어(SL) [Pizza]\n",
    " - 시간부사(MAG) [오늘, 내일, 모래]\n",
    " - 한국어 품사 태그 비교표 https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판교 오늘 피자 주문 \n"
     ]
    }
   ],
   "source": [
    "tagged_text = ''\n",
    "for pos_tags in morpphed_text:\n",
    "    if (pos_tags[1] in ['NNG','MAG', 'NNP','SL'] and len(pos_tags[0]) > 1): #Check only Noun\n",
    "        feature_value = pos_tags[0]\n",
    "        tagged_text = tagged_text + pos_tags[0] + ' '\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Intent 학습 Data의 구성 (Text Representation)\n",
    "\n",
    "- Intent 성능 향상을 위해 parse한 Text Data를 represent화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagloc tagdate tagmenu 주문  \n"
     ]
    }
   ],
   "source": [
    "pattern = ''\n",
    "for word in tagged_text.split(' '):\n",
    "    entity = list(filter(lambda key:word in dict_entity[key],list(dict_entity.keys())))\n",
    "    if(len(entity) > 0): \n",
    "        pattern = pattern + 'tag' + entity[0] + ' '\n",
    "    else:\n",
    "        pattern = pattern + word + ' '\n",
    "\n",
    "print(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data augmentation (Entity and Pattern)\n",
    " - 각 의도별 Pattern text를 entity의 N 배수로 Augmenatation 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augmentation_pattern(pattern, dict_entity):\n",
    "    #입력된 패턴을 List로 바꿈\n",
    "    aug_pattern = pattern.split(' ')\n",
    "    #Augment된 Text List\n",
    "    augmented_text_list = []\n",
    "    #copy를 위한 임시 List\n",
    "    temp_aug = []\n",
    "    for i in range(0,len(aug_pattern)):\n",
    "        #Entity에 해당하는 값일 경우 Entity List를 가져옴\n",
    "        if(aug_pattern[i].find(\"tag\") > -1):\n",
    "            dict_list = dict_entity[aug_pattern[i].replace(\"tag\",\"\")]\n",
    "            #각 Entity별로 값을 append하면서 Pattern구성\n",
    "            for j in range(0,len(dict_list)):\n",
    "                #최초 Entity값은 그냥 추가만함\n",
    "                if(i == 0):\n",
    "                    augmented_text_list.append(dict_list[j] + \" \")\n",
    "                elif(j == 1):\n",
    "                    augmented_text_list = list(filter(lambda word:len(word.split(' ')) == i+1 ,augmented_text_list))\n",
    "                    copy_data_order = augmented_text_list * (len(dict_list)-2)\n",
    "                    augmented_text_list = list(map(lambda x:x + dict_list[j] + \" \",augmented_text_list))\n",
    "                    augmented_text_list = augmented_text_list + temp_aug + copy_data_order\n",
    "                else:\n",
    "                    #List의 수를 체크하여 값을 추가\n",
    "                    temp_aug = list(filter(lambda word:len(word.split(' ')) == i+1 ,augmented_text_list))\n",
    "                    temp_aug = list(map(lambda x:x + dict_list[j] + \" \" ,temp_aug))\n",
    "                    #추가된 List를 위해 기존 값 삭제\n",
    "                    if(j != 0):\n",
    "                        augmented_text_list = augmented_text_list[0:len(augmented_text_list) - len(temp_aug)]\n",
    "                    augmented_text_list = augmented_text_list + temp_aug\n",
    "        #Entity추가 대상이 아닐 경우 Pattern만 추가\n",
    "        else:\n",
    "            augmented_text_list = list(map(lambda x:x + aug_pattern[i] + \" \",augmented_text_list))\n",
    "        #N*N으로 증가시키기 위한 List\n",
    "        temp_aug = augmented_text_list\n",
    "    return augmented_text_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['판교 내일 햄버거 주문   ',\n",
       " '야탑 내일 햄버거 주문   ',\n",
       " '서현 내일 햄버거 주문   ',\n",
       " '판교 오늘 햄버거 주문   ',\n",
       " '야탑 오늘 햄버거 주문   ',\n",
       " '서현 오늘 햄버거 주문   ',\n",
       " '판교 모래 햄버거 주문   ',\n",
       " '야탑 모래 햄버거 주문   ',\n",
       " '서현 모래 햄버거 주문   ',\n",
       " '판교 내일 피자 주문   ',\n",
       " '야탑 내일 피자 주문   ',\n",
       " '서현 내일 피자 주문   ',\n",
       " '판교 오늘 피자 주문   ',\n",
       " '야탑 오늘 피자 주문   ',\n",
       " '서현 오늘 피자 주문   ',\n",
       " '판교 모래 피자 주문   ',\n",
       " '야탑 모래 피자 주문   ',\n",
       " '서현 모래 피자 주문   ',\n",
       " '판교 내일 치킨 주문   ',\n",
       " '야탑 내일 치킨 주문   ',\n",
       " '서현 내일 치킨 주문   ',\n",
       " '판교 오늘 치킨 주문   ',\n",
       " '야탑 오늘 치킨 주문   ',\n",
       " '서현 오늘 치킨 주문   ',\n",
       " '판교 모래 치킨 주문   ',\n",
       " '야탑 모래 치킨 주문   ',\n",
       " '서현 모래 치킨 주문   ']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_text_list = augmentation_pattern(pattern, dict_entity)\n",
    "augmented_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIO Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NER을 위한 Full Train Text 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
