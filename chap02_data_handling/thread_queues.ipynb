{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tensorflow 에서는 정해진 사이즈의 큐를 중심으로 큐에 데이터를 넣는 행위와 빼서 사용하는 행위를 멀티 쓰레드 기반으로 수행할 수 있도록 라이브러리를 제공하고 있다. 실제로 대량의 데이터를 Tensowflow 를 통해서 훈련하고자 할 경우 발생할 수 있는 메모리 오버플러우 등을 회피 할 수 있는 효과적인 수단으로 사용될 수 있다. 어떤 식으로 Queue 를 사용하여 Thread 처리를 하는 지 예제를 통해서 살펴 보도록 하자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n",
      "data : [1 2 3 4 4 5] , lable : 5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(['./data/test.csv'])\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "record_defaults = [[1], [1], [1], [1], [1]]\n",
    "col1, col2, col3, col4, col5 = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "feature = tf.stack([col1, col2, col3, col4, col4, col5])\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      \n",
    "    for i in range(10):\n",
    "        example, label = sess.run([feature, col5])     \n",
    "        print(\"data : {0} , lable : {1}\".format(example,label))\n",
    "                   \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# filename_pattern = '/home/dev/hoyai_jupyter/chap02_data_handling/data/*.csv'\n",
    "# filename_list = tf.train.match_filenames_once(filename_pattern)\n",
    "# filename_queue = tf.train.string_input_producer(filename_list, shuffle=True, num_epochs=2)\n",
    "# filename_queue = tf.train.string_input_producer(['data/test.csv','data/test.csv'])\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(['./data/test.csv'])\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[1], [1], [1], [1], [1]]\n",
    "col1,col2,col3,col4,col5 = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "features = tf.stack([col1,col2,col3,col4,col5])\n",
    "\n",
    "# min_after_dequeue = 5\n",
    "# capacity = min_after_dequeue + 3 * batch_size\n",
    "# queue = tf.RandomShuffleQueue(\n",
    "#     capacity=capacity, \n",
    "#     min_after_dequeue=min_after_dequeue, \n",
    "#     dtypes=tf.int32, \n",
    "#     shapes=[5,]\n",
    "# )\n",
    "#enqueue_op = queue.enqueue(features)\n",
    "\n",
    "batch_size = 1\n",
    "queue = tf.FIFOQueue(10, tf.int32, shapes=[5,])\n",
    "enqueue_op = queue.enqueue(features)\n",
    "inputs = queue.dequeue_many(batch_size)\n",
    "#tf.tables_initializer()\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * 2)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "coord = tf.train.Coordinator()\n",
    "enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "\n",
    "try:\n",
    "    for step in range(10):\n",
    "        print(step)\n",
    "        if coord.should_stop():\n",
    "            print(\"stop\")\n",
    "            break\n",
    "        print(sess.run(features))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    coord.request_stop(e)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(enqueue_threads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "TRAINING_ITERS = 100\n",
    "\n",
    "# Features are length-100 vectors of floats\n",
    "feature_input = tf.placeholder(tf.float32, shape=[100])\n",
    "# Labels are scalar integers.\n",
    "label_input = tf.placeholder(tf.int32, shape=[])\n",
    "\n",
    "# Alternatively, could do:\n",
    "# feature_batch_input = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "# label_batch_input = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "q = tf.FIFOQueue(100, [tf.float32, tf.int32], shapes=[[100], []])\n",
    "enqueue_op = q.enqueue([label_input, feature_input])\n",
    "\n",
    "# For batch input, do:\n",
    "# enqueue_op = q.enqueue_many([label_batch_input, feature_batch_input])\n",
    "\n",
    "label_batch, feature_batch = q.dequeue_many(BATCH_SIZE)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "def load_and_enqueue():\n",
    "  with open(...) as feature_file, open(...) as label_file:\n",
    "    while True:\n",
    "      feature_array = numpy.fromfile(feature_file, numpy.float32, 100)\n",
    "      if not feature_array:\n",
    "        return\n",
    "      label_value = numpy.fromfile(feature_file, numpy.int32, 1)[0]\n",
    "\n",
    "      sess.run(enqueue_op, feed_dict={feature_input: feature_array,\n",
    "                                      label_input: label_value})\n",
    "\n",
    "# Start a thread to enqueue data asynchronously, and hide I/O latency.\n",
    "t = threading.Thread(target=load_and_enqueue)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9542c3d6e27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize placeholders for feeding in to the queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpl_queue_screens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"queue_inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpl_queue_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"queue_targets_cnt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize placeholders for feeding in to the queue\n",
    "pl_queue_screens = tf.placeholder(tf.float32, shape=[config.seq_length, config.image_size, config.image_size, config.input_channels], name=\"queue_inputs\")\n",
    "pl_queue_targets = tf.placeholder(tf.uint8, shape=[config.seq_length], name=\"queue_targets_cnt\")\n",
    "\n",
    "#  ...\n",
    "\n",
    "capacity = config.min_after_dequeue + 10 * (config.num_gpus*config.batch_size)\n",
    "q = tf.RandomShuffleQueue(\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=config.min_after_dequeue,\n",
    "    dtypes=[tf.float32, tf.uint8],\n",
    "    shapes=[[config.seq_length, config.image_size, config.image_size, config.input_channels], [config.seq_length]]\n",
    ")\n",
    "\n",
    "\n",
    "# ..and finally the enqueue operation for adding a single sequence\n",
    "enqueue_op = q.enqueue([seq_proc, pl_queue_targets])\n",
    "\n",
    "# Misc queue operations\n",
    "examples_in_queue = q.size()\n",
    "queue_close_op = q.close(cancel_pending_enqueues=True)\n",
    "\n",
    "# This must be the input for the training operation\n",
    "inputs_batch_queue, targets_batch_queue = q.dequeue_many(config.batch_size)\n",
    "\n",
    "# Placeholders for training and evaluation\n",
    "batch_screens = tf.placeholder_with_default(inputs_batch_queue, [None, config.seq_length, config.image_size, config.image_size, config.input_channels], name=\"model_inputs\")\n",
    "batch_targets = tf.placeholder_with_default(targets_batch_queue, [None, config.seq_length], name=\"model_targets_cnt\")\n",
    "dropout_keep_prob = tf.placeholder_with_default(tf.constant(1.0), shape=[], name=\"dropout_keep_prob\")\n",
    "\n",
    "# ...\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "# Now we start a number of threads that read from disk (numpy) array and feed it to the queue\n",
    "# Coordinator for threads\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Start the data loading + preprocessing threads\n",
    "threads = []\n",
    "for _ in range(config.num_preproc_threads):\n",
    "\t\n",
    "\t# This is the method that runs in the threads and feeds examples to the queue\n",
    "    t = threading.Thread(target=load_preproc_enqueue_thread, args=(\n",
    "        sess, coord, enqueue_op, pl_queue_screens, pl_queue_targets,\n",
    "    \t# additional arguments ...     \n",
    "    ))\n",
    "\n",
    "    t.setDaemon(True)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "    coord.register_thread(t)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "num_examples_in_queue = sess.run(examples_in_queue)\n",
    "while num_examples_in_queue < config.min_after_dequeue:\n",
    "    num_examples_in_queue = sess.run(examples_in_queue)\n",
    "    for t in threads:\n",
    "        if not t.isAlive():\n",
    "            coord.request_stop()\n",
    "            raise ValueError(\"One or more enqueuing threads crashed...\")\n",
    "\n",
    "    print(\"Filling up queue with training examples: %i/%i\" % (num_examples_in_queue, config.min_after_dequeue))\n",
    "    time.sleep(1)\n",
    "\n",
    "# ...\n",
    "\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "# ...\n",
    "# For your training operation use batch_screens and batch_targets as inputs\n",
    "# Look at the use of tf.placeholder_with_default() => if no feed_dict{} is fed in then the placeholder will fetch examples from the queue\n",
    "# For your validation data, you can just use the placeholders/feeddict.\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "def load_preproc_enqueue_thread(sess, coord, enqueue_op, pl_queue_screens, pl_queue_targets):\n",
    "\t\n",
    "\t# MODIFY THIS FUNCTION FOR LOADING SLICES FROM YOUR INPUT TENSOR AND FEEDING INTO QUEUE PLACEHOLDERS\n",
    "\n",
    "    # Fetch the HDF5 files from disk...\n",
    "    filenames_queue = glob.glob(os.path.join(dataset_path, \"train/*.h5\"))\n",
    "    filenames_queue.sort()\n",
    "\n",
    "    while not coord.should_stop():\n",
    "\n",
    "        # Shuffle the filenames each time we have fed everything\n",
    "        random.shuffle(filenames_queue)\n",
    "\n",
    "        for filename in filenames_queue:\n",
    "\n",
    "            # Read 100 examples from HDF5 file, shuffle files within file.\n",
    "            # Optionally also perform mean subtraction and normalization.\n",
    "            # Sequences can also be tiled if the examples are padded with zeros\n",
    "            # after one cycle length.\n",
    "            screens, _, count_labels, cycle_lengths, residual_frames, _ = \\\n",
    "                read_examples_from_hdf5(\n",
    "                    filename, shuffle=True, data_whitening=data_whitening,\n",
    "                    expand_dims=expand_dims, convert_to_grayscale=convert_to_grayscale\n",
    "                )\n",
    "\n",
    "            # Feed Dictionary without the labels\n",
    "            feed_dict = {\n",
    "                pl_queue_screens: screens[index,],\n",
    "                pl_queue_targets: targets,\n",
    "                pl_flip_image: random_flip,\n",
    "                pl_brightness_delta: random_brightness_delta,\n",
    "                pl_contrast_factor: random_contrast_factor\n",
    "            }\n",
    "\n",
    "            # Feed examples to the queue\n",
    "            try:\n",
    "                sess.run(enqueue_op, feed_dict=feed_dict)\n",
    "            except tf.errors.CancelledError:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
