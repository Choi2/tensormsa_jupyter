{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Transfer&Train&Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ID=nn00011\n",
      "Workflow Version=2\n",
      "\n",
      "Network Config : {'config': {'num_classes': 10, 'type': 'category', 'learnrate': 0.001, 'layeroutputs': 32}, 'param': {'traincnt': 2, 'epoch': 1, 'predictcnt': 10, 'batch_size': 150}, 'layer1': {'maxpoolstride': [2, 2], 'layercnt': 2, 'cnnfilter': [3, 3], 'padding': 'SAME', 'droprate': '0.8', 'maxpoolmatrix': [2, 2], 'type': 'cnn', 'cnnstride': [1, 1], 'active': 'relu'}, 'layer2': {'maxpoolstride': [2, 2], 'layercnt': 1, 'cnnfilter': [3, 3], 'padding': 'SAME', 'droprate': '0.8', 'maxpoolmatrix': [2, 2], 'type': 'cnn', 'cnnstride': [1, 1], 'active': 'relu'}, 'labels': [], 'out': {'node_out': 625, 'active': 'softmax', 'padding': 'SAME'}}\n",
      "\n",
      "Train Data Config : {'preprocess': {'channel': 3, 'x_size': 32, 'y_size': 32}, 'source_path': '/hoya_src_root/nn00011/2/datasrc', 'store_path': '/hoya_str_root/nn00011/2/datasrc'}\n",
      "\n",
      "Eval Config : {}\n",
      "\n",
      "Eval Data Config : {'preprocess': {'channel': 3, 'x_size': 32, 'y_size': 32}, 'source_path': '/hoya_src_root/nn00011/2/evaldata', 'store_path': '/hoya_str_root/nn00011/2/evaldata'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json, os\n",
    "\n",
    "url = \"{0}:{1}\".format(os.environ['HOSTNAME'] , \"8000\")\n",
    "\n",
    "nn_id = \"nn00011\"\n",
    "biz_cate = \"ERP\"\n",
    "biz_sub_cate = \"MRO\"\n",
    "nn_title = \"MRO Image Classification\"\n",
    "nn_desc = \"MRO Image Classification\"\n",
    "nn_wf_ver_info = \"MRO Image Classification\"\n",
    "use_flag = \"Y\"\n",
    "dirstr = \"purpose?\"\n",
    "config = \"N\"\n",
    "network_type = \"cnn\"\n",
    "node_sub_menu = \"data_image\"\n",
    "\n",
    "# get Active workflow version\n",
    "wf_ver_id = 0\n",
    "if wf_ver_id == 0:\n",
    "    resp = requests.get('http://' + url + '/api/v1/type/common/target/nninfo/nnid/'+nn_id+'/version/')\n",
    "    data = json.loads(resp.json())\n",
    "\n",
    "    # get Max workflow version\n",
    "    for config in data:\n",
    "        if config[\"fields\"][\"nn_wf_ver_id\"] > wf_ver_id:\n",
    "            wf_ver_id = config[\"fields\"][\"nn_wf_ver_id\"]\n",
    "\n",
    "wf_ver_id = str(wf_ver_id)\n",
    "\n",
    "print(\"Network ID=\"+nn_id)\n",
    "print(\"Workflow Version=\"+wf_ver_id)\n",
    "print(\"\")\n",
    "\n",
    "def spaceprint(val, cnt):\n",
    "    leng = len(str(val))\n",
    "    cnt = cnt - leng\n",
    "    restr = \"\"\n",
    "    for i in range(cnt):\n",
    "        restr += \" \"\n",
    "    restr = restr+str(val)\n",
    "    return restr\n",
    "\n",
    "node = \"netconf_node\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/netconf/detail/cnn/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                         \"param\":{\"epoch\":1\n",
    "                                  ,\"traincnt\": 2,\n",
    "                                     \"batch_size\":150,\n",
    "                                     \"predictcnt\": 10\n",
    "                         },\n",
    "                         \"config\": {\"num_classes\":10,\n",
    "                                    \"learnrate\": 0.001,\n",
    "                                     \"layeroutputs\":32,\n",
    "                                     \"type\":\"category\"\n",
    "                                     }\n",
    "                         ,\"layer1\": {\"type\": \"cnn\",\n",
    "                                     \"active\": \"relu\",\n",
    "                                     \"cnnfilter\": [3, 3],\n",
    "                                     \"cnnstride\": [1, 1],\n",
    "                                     \"maxpoolmatrix\": [2, 2],\n",
    "                                     \"maxpoolstride\": [2, 2],\n",
    "                                     \"padding\": \"SAME\",\n",
    "                                     \"droprate\": \"0.8\",\n",
    "                                     \"layercnt\":2\n",
    "                                    }\n",
    "                         ,\"layer2\": {\"type\": \"cnn\",\n",
    "                                     \"active\": \"relu\",\n",
    "                                     \"cnnfilter\": [3, 3],\n",
    "                                     \"cnnstride\": [1, 1],\n",
    "                                     \"maxpoolmatrix\": [2, 2],\n",
    "                                     \"maxpoolstride\": [2, 2],\n",
    "                                     \"padding\": \"SAME\",\n",
    "                                     \"droprate\": \"0.8\",\n",
    "                                     \"layercnt\":1\n",
    "                                    }\n",
    "                          ,\"out\": {\"active\": \"softmax\",\n",
    "                                   \"node_out\": 625,\n",
    "                                   \"padding\": \"SAME\"\n",
    "                                }\n",
    "        ,\"labels\":[]\n",
    "                        })\n",
    "netconf = json.loads(resp.json())\n",
    "print(\"Network Config : {0}\".format(netconf))\n",
    "print(\"\")\n",
    "\n",
    "node = \"datasrc\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/imgdata/src/local/form/file/prg/source/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                            \"preprocess\": {\"x_size\": 32,\n",
    "                                        \"y_size\": 32,\n",
    "                                        \"channel\":3}\n",
    "                         \n",
    "\n",
    "                     })\n",
    "dataconf = json.loads(resp.json())\n",
    "print(\"Train Data Config : {0}\".format(dataconf))\n",
    "print(\"\")\n",
    "\n",
    "node = \"eval_node\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/netconf/detail/cnn/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',json={})\n",
    "evalconf = json.loads(resp.json())\n",
    "print(\"Eval Config : {0}\".format(evalconf))\n",
    "print(\"\")\n",
    "\n",
    "node = 'evaldata'\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/imgdata/src/local/form/file/prg/source/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                            \"preprocess\": {\"x_size\": 32,\n",
    "                                        \"y_size\": 32,\n",
    "                                        \"channel\":3}\n",
    "\n",
    "                     })\n",
    "edataconf = json.loads(resp.json())\n",
    "print(\"Eval Data Config : {0}\".format(edataconf))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning & Eval Data Transfer\n",
    "(CNN Network Train을 할 수 있게 Data를 특정 장소에 전송해 준다.)<br>\n",
    "\n",
    "아래 API의 경우 Test Data인지 Train Data인지 선택할수 있는 Node 정보를 모두 가져와 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get file node list\n",
      "{'nn_wf_node_name': 'evaldata', 'nn_wf_node_desc': 'Evaluation Data Node', 'nn_wf_node_id': 'nn00011_2_evaldata'}\n",
      "{'nn_wf_node_name': 'datasrc', 'nn_wf_node_desc': 'Train Data Node', 'nn_wf_node_id': 'nn00011_2_datasrc'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get workflow node list info (train, eval)\n",
    "resp = requests.get('http://' + url + '/api/v1/type/wf/state/data/detail/upload/file/nnid/'+nn_id+'/ver/'+wf_ver_id+'/dir/'+node_sub_menu+'/')\n",
    "datalist = json.loads(resp.json())\n",
    "\n",
    "print(\"get file node list\")\n",
    "for node in datalist:\n",
    "    print(datalist[node])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 API는 한개의 파일을 Train Folder & Test Folder 에 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create file node list\n",
      "{'File0': {'File': 'File Create.(/hoya_src_root/nn00011/2/evaldata/sample_cnn_img.zip)'}, 'File1': {'File': 'File Create.(/hoya_src_root/nn00011/2/evaldata/sample_cnn_img.zip)'}}\n",
      "{'File0': {'File': 'File Create.(/hoya_src_root/nn00011/2/datasrc/sample_cnn_img.zip)'}, 'File1': {'File': 'File Create.(/hoya_src_root/nn00011/2/datasrc/sample_cnn_img.zip)'}}\n"
     ]
    }
   ],
   "source": [
    "# Train Folder에 Data를 위치 시킬지 Eval Folder에 Data를 위치 시킬지 결정후 전송해야 한다.\n",
    "print(\"create file node list\")\n",
    "for node in datalist:\n",
    "    typepath = datalist[node][\"nn_wf_node_name\"]\n",
    "\n",
    "    files = {'file1': open('/home/dev/hoyai/demo/data/cat_vs_dog.zip','rb'),\n",
    "             'file2': open('/home/dev/hoyai/demo/data/sample_cnn_img.zip','rb')}\n",
    "\n",
    "    resp = requests.post('http://' + url + '/api/v1/type/wf/state/data/detail/upload/file/nnid/'+nn_id+'/ver/'+wf_ver_id+'/dir/'+typepath+'/',\n",
    "                         files=files)\n",
    "    data = json.loads(resp.json())\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network Training\n",
    "(CNN Network Training을 실행한다.)<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trainning ..................................................']\n",
      "['Global Step: 12, Training Batch Accuracy: 17.65%, Cost: 244.769']\n",
      "\n",
      "         ['   motor', '     dog', '     car', '   glove', 'airplane', '     cat', '    bolt']\n",
      "         ====================================================================================\n",
      "   motor ['       0', '       0', '       2', '       0', '       1', '       0', '       0'] 0.0%\n",
      "     dog ['       0', '       0', '       1', '       0', '       0', '       0', '       0'] 0.0%\n",
      "     car ['       0', '       0', '       3', '       0', '       0', '       0', '       0'] 100.0%\n",
      "   glove ['       0', '       0', '       1', '       0', '       1', '       0', '       1'] 0.0%\n",
      "airplane ['       0', '       0', '       2', '       0', '       1', '       0', '       0'] 33.33%\n",
      "     cat ['       0', '       0', '       1', '       0', '       0', '       0', '       0'] 0.0%\n",
      "    bolt ['       0', '       0', '       1', '       0', '       1', '       0', '       1'] 33.33%\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/runmanager/state/train/nnid/'+nn_id+'/ver/'+wf_ver_id+'/')\n",
    "data = json.loads(resp.json())\n",
    "\n",
    "for train in data:\n",
    "    if train != None and train != \"\" and train != {} and train != \"status\" and train != \"result\":\n",
    "        try:\n",
    "            for tr in train[\"TrainResult\"]:\n",
    "                print(tr)\n",
    "        except:\n",
    "            maxcnt = 0\n",
    "            line = \"\"\n",
    "            for label in train[\"labels\"]:\n",
    "                if maxcnt<len(label):\n",
    "                    maxcnt = len(label)\n",
    "\n",
    "            for i in range(len(train[\"labels\"])):\n",
    "                for j in range(maxcnt+4):\n",
    "                    line += \"=\"\n",
    "\n",
    "            label_sub = []\n",
    "            for label in train[\"labels\"]:\n",
    "                label = spaceprint(label,maxcnt)\n",
    "                label_sub.append(label)\n",
    "\n",
    "            space = \"\"\n",
    "            for s in range(maxcnt):\n",
    "                space +=\" \"\n",
    "\n",
    "            print(space, label_sub)\n",
    "            print(space, line)\n",
    "            for i in range(len(train[\"labels\"])):\n",
    "                truecnt = 0\n",
    "                totcnt = 0\n",
    "                predict_sub = []\n",
    "                for j in range(len(train[\"predicts\"][i])):\n",
    "                    pred = spaceprint(train[\"predicts\"][i][j],maxcnt)\n",
    "\n",
    "                    predict_sub.append(pred)\n",
    "                    totcnt += int(pred)\n",
    "                    # print(train[\"labels\"].index(train[\"labels\"][i]))\n",
    "                    if train[\"labels\"].index(train[\"labels\"][i]) == j:\n",
    "                        truecnt = int(pred)\n",
    "                if totcnt == 0:\n",
    "                    percent = 0\n",
    "                else:\n",
    "                    percent = round(truecnt/totcnt*100,2)\n",
    "                print(spaceprint(train[\"labels\"][i],maxcnt), predict_sub, str(percent)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network Predict\n",
    "(CNN Network Predict를 실행한다.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileName = 2car.jpg\n",
      "['car', 'cat', 'bolt', 'dog', 'airplane', 'glove', 'motor']\n",
      "[100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 1air.jpg\n",
      "['bolt', 'car', 'airplane', 'dog', 'glove', 'cat', 'motor']\n",
      "[99.999988, 1.4999999999999999e-05, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 2air.jpg\n",
      "['car', 'airplane', 'bolt', 'glove', 'dog', 'cat', 'motor']\n",
      "[92.748576, 4.583563, 2.6678629999999997, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 1glove.jpg\n",
      "['airplane', 'bolt', 'glove', 'dog', 'car', 'cat', 'motor']\n",
      "[100.0, 1e-06, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 2motor.jpg\n",
      "['airplane', 'bolt', 'car', 'cat', 'glove', 'dog', 'motor']\n",
      "[73.07287500000001, 26.695204, 0.231923, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 2glove.jpg\n",
      "['glove', 'car', 'airplane', 'cat', 'dog', 'bolt', 'motor']\n",
      "[99.855965, 0.117309, 0.026729, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 1motor.jpg\n",
      "['airplane', 'bolt', 'cat', 'glove', 'car', 'dog', 'motor']\n",
      "[100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 1car.jpg\n",
      "['car', 'bolt', 'cat', 'airplane', 'glove', 'dog', 'motor']\n",
      "[100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 2bolt.jpg\n",
      "['bolt', 'glove', 'airplane', 'cat', 'car', 'dog', 'motor']\n",
      "[99.99934400000001, 0.00063, 2.3e-05, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "FileName = 1bolt.jpg\n",
      "['airplane', 'dog', 'bolt', 'car', 'glove', 'cat', 'motor']\n",
      "[100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = {\n",
    "         'files000001':  open('/home/dev/hoyai/demo/data/airplane/1air.jpg','rb')\n",
    "        ,'files000002':  open('/home/dev/hoyai/demo/data/airplane/2air.jpg','rb')\n",
    "        ,'files000003':  open('/home/dev/hoyai/demo/data/bolt/1bolt.jpg','rb')\n",
    "        ,'files000004':  open('/home/dev/hoyai/demo/data/bolt/2bolt.jpg','rb')\n",
    "        ,'files000005':  open('/home/dev/hoyai/demo/data/car/1car.jpg','rb')\n",
    "        ,'files000006':  open('/home/dev/hoyai/demo/data/car/2car.jpg','rb')\n",
    "        ,'files000007':  open('/home/dev/hoyai/demo/data/glove/1glove.jpg','rb')\n",
    "        ,'files000008':  open('/home/dev/hoyai/demo/data/glove/2glove.jpg','rb')\n",
    "        ,'files000009':  open('/home/dev/hoyai/demo/data/motor/1motor.jpg','rb')\n",
    "        ,'files000010':  open('/home/dev/hoyai/demo/data/motor/2motor.jpg','rb')\n",
    "        }\n",
    "restURL = 'http://' + url + '/api/v1/type/service/state/predict/type/'+network_type+'/nnid/'+nn_id+'/ver/'+wf_ver_id+'/'\n",
    "\n",
    "resp = requests.post(restURL,\n",
    "                     files=files\n",
    "                     )\n",
    "data = json.loads(resp.json())\n",
    "\n",
    "for train in data:\n",
    "    print(\"FileName = \"+train)\n",
    "    print(data[train]['key'])\n",
    "    print(data[train]['val'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
