{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Transfer&Train&Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ID=nn00004\n",
      "Workflow Version=18\n",
      "\n",
      "Network Config : {'layer1': {'cnnfilter': [3, 3], 'maxpoolstride': [2, 2], 'maxpoolmatrix': [2, 2], 'cnnstride': [1, 1], 'padding': 'SAME', 'layercnt': 2, 'active': 'relu', 'droprate': '0.8', 'type': 'cnn'}, 'layer2': {'cnnfilter': [3, 3], 'maxpoolstride': [2, 2], 'maxpoolmatrix': [2, 2], 'cnnstride': [1, 1], 'padding': 'SAME', 'layercnt': 1, 'active': 'relu', 'droprate': '0.8', 'type': 'cnn'}, 'out': {'node_out': 625, 'active': 'softmax', 'padding': 'SAME'}, 'param': {'epoch': 20, 'traincnt': 5, 'batch_size': 10000, 'predictcnt': 10}, 'labels': [], 'config': {'learnrate': 0.001, 'layeroutputs': 32, 'type': 'category', 'num_classes': 10}}\n",
      "\n",
      "Train Data Config : {'store_path': '/hoya_str_root/nn00004/18/datasrc', 'preprocess': {'channel': 3, 'y_size': 32, 'x_size': 32}, 'source_path': '/hoya_src_root/nn00004/18/datasrc'}\n",
      "\n",
      "Eval Config : {}\n",
      "\n",
      "Eval Data Config : {'store_path': '/hoya_str_root/nn00004/18/evaldata', 'preprocess': {'channel': 3, 'y_size': 32, 'x_size': 32}, 'source_path': '/hoya_src_root/nn00004/18/evaldata'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json, os\n",
    "\n",
    "url = \"{0}:{1}\".format(os.environ['HOSTNAME'] , \"8000\")\n",
    "\n",
    "nn_id = \"nn00004\"\n",
    "biz_cate = \"ERP\"\n",
    "biz_sub_cate = \"MRO\"\n",
    "nn_title = \"MRO Image Classification\"\n",
    "nn_desc = \"MRO Image Classification\"\n",
    "nn_wf_ver_info = \"MRO Image Classification\"\n",
    "use_flag = \"Y\"\n",
    "dirstr = \"purpose?\"\n",
    "config = \"N\"\n",
    "network_type = \"cnn\"\n",
    "node_sub_menu = \"data_image\"\n",
    "\n",
    "# get workflow version info\n",
    "resp = requests.get('http://' + url + '/api/v1/type/common/target/nninfo/nnid/'+nn_id+'/version/')\n",
    "data = json.loads(resp.json())\n",
    "\n",
    "# get Active workflow version\n",
    "wf_ver_id = 0\n",
    "data = sorted(data, key=lambda k: k['pk'])\n",
    "for config in data:\n",
    "    if config[\"fields\"][\"active_flag\"] == \"Y\":\n",
    "        wf_ver_id = config[\"pk\"]\n",
    "\n",
    "wf_ver_id = str(wf_ver_id)\n",
    "\n",
    "print(\"Network ID=\"+nn_id)\n",
    "print(\"Workflow Version=\"+wf_ver_id)\n",
    "print(\"\")\n",
    "\n",
    "def spaceprint(val, cnt):\n",
    "    leng = len(str(val))\n",
    "    cnt = cnt - leng\n",
    "    restr = \"\"\n",
    "    for i in range(cnt):\n",
    "        restr += \" \"\n",
    "    restr = restr+str(val)\n",
    "    return restr\n",
    "\n",
    "node = \"netconf_node\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/netconf/detail/cnn/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                         \"param\":{\"epoch\":20\n",
    "                                  ,\"traincnt\": 5,\n",
    "                                     \"batch_size\":10000,\n",
    "                                     \"predictcnt\": 10\n",
    "                         },\n",
    "                         \"config\": {\"num_classes\":10,\n",
    "                                    \"learnrate\": 0.001,\n",
    "                                     \"layeroutputs\":32,\n",
    "                                     \"type\":\"category\"\n",
    "                                     }\n",
    "                         ,\"layer1\": {\"type\": \"cnn\",\n",
    "                                     \"active\": \"relu\",\n",
    "                                     \"cnnfilter\": [3, 3],\n",
    "                                     \"cnnstride\": [1, 1],\n",
    "                                     \"maxpoolmatrix\": [2, 2],\n",
    "                                     \"maxpoolstride\": [2, 2],\n",
    "                                     \"padding\": \"SAME\",\n",
    "                                     \"droprate\": \"0.8\",\n",
    "                                     \"layercnt\":2\n",
    "                                    }\n",
    "                         ,\"layer2\": {\"type\": \"cnn\",\n",
    "                                     \"active\": \"relu\",\n",
    "                                     \"cnnfilter\": [3, 3],\n",
    "                                     \"cnnstride\": [1, 1],\n",
    "                                     \"maxpoolmatrix\": [2, 2],\n",
    "                                     \"maxpoolstride\": [2, 2],\n",
    "                                     \"padding\": \"SAME\",\n",
    "                                     \"droprate\": \"0.8\",\n",
    "                                     \"layercnt\":1\n",
    "                                    }\n",
    "                          ,\"out\": {\"active\": \"softmax\",\n",
    "                                   \"node_out\": 625,\n",
    "                                   \"padding\": \"SAME\"\n",
    "                                }\n",
    "        ,\"labels\":[]\n",
    "                        })\n",
    "netconf = json.loads(resp.json())\n",
    "print(\"Network Config : {0}\".format(netconf))\n",
    "print(\"\")\n",
    "\n",
    "node = \"datasrc\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/imgdata/src/local/form/file/prg/source/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                            \"preprocess\": {\"x_size\": 32,\n",
    "                                        \"y_size\": 32,\n",
    "                                        \"channel\":3}\n",
    "                         \n",
    "\n",
    "                     })\n",
    "dataconf = json.loads(resp.json())\n",
    "print(\"Train Data Config : {0}\".format(dataconf))\n",
    "print(\"\")\n",
    "\n",
    "node = \"eval_node\"\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/netconf/detail/cnn/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',json={})\n",
    "evalconf = json.loads(resp.json())\n",
    "print(\"Eval Config : {0}\".format(evalconf))\n",
    "print(\"\")\n",
    "\n",
    "node = 'evaldata'\n",
    "resp = requests.put('http://' + url + '/api/v1/type/wf/state/imgdata/src/local/form/file/prg/source/nnid/'+nn_id+'/ver/'+wf_ver_id+'/node/'+node+'/',\n",
    "                     json={\n",
    "                            \"preprocess\": {\"x_size\": 32,\n",
    "                                        \"y_size\": 32,\n",
    "                                        \"channel\":3}\n",
    "\n",
    "                     })\n",
    "edataconf = json.loads(resp.json())\n",
    "print(\"Eval Data Config : {0}\".format(edataconf))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning & Eval Data Transfer\n",
    "(CNN Network Train을 할 수 있게 Data를 특정 장소에 전송해 준다.)<br>\n",
    "\n",
    "아래 API의 경우 Test Data인지 Train Data인지 선택할수 있는 Node 정보를 모두 가져와 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get file node list\n",
      "{'nn_wf_node_desc': 'Train Data Node', 'nn_wf_node_id': 'nn00004_18_datasrc', 'nn_wf_node_name': 'datasrc'}\n",
      "{'nn_wf_node_desc': 'Evaluation Data Node', 'nn_wf_node_id': 'nn00004_18_evaldata', 'nn_wf_node_name': 'evaldata'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get workflow node list info (train, eval)\n",
    "resp = requests.get('http://' + url + '/api/v1/type/wf/state/data/detail/upload/file/nnid/'+nn_id+'/ver/'+wf_ver_id+'/dir/'+node_sub_menu+'/')\n",
    "datalist = json.loads(resp.json())\n",
    "\n",
    "print(\"get file node list\")\n",
    "for node in datalist:\n",
    "    print(datalist[node])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 API는 한개의 파일을 Train Folder & Test Folder 에 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create file node list\n",
      "{'File0': {'File': 'File Create.(/hoya_src_root/nn00004/18/datasrc/sample_cnn_img.zip1)'}, 'File1': {'File': 'File Create.(/hoya_src_root/nn00004/18/datasrc/sample_cnn_img.zip1)'}}\n",
      "{'File0': {'File': 'File Create.(/hoya_src_root/nn00004/18/evaldata/sample_cnn_img.zip1)'}, 'File1': {'File': 'File Create.(/hoya_src_root/nn00004/18/evaldata/sample_cnn_img.zip1)'}}\n"
     ]
    }
   ],
   "source": [
    "# Train Folder에 Data를 위치 시킬지 Eval Folder에 Data를 위치 시킬지 결정후 전송해야 한다.\n",
    "print(\"create file node list\")\n",
    "for node in datalist:\n",
    "    typepath = datalist[node][\"nn_wf_node_name\"]\n",
    "\n",
    "    files = {'file1': open('/home/dev/hoyai/demo/data/cat_vs_dog.zip','rb'),\n",
    "             'file2': open('/home/dev/hoyai/demo/data/sample_cnn_img.zip','rb')}\n",
    "\n",
    "    resp = requests.post('http://' + url + '/api/v1/type/wf/state/data/detail/upload/file/nnid/'+nn_id+'/ver/'+wf_ver_id+'/dir/'+typepath+'/',\n",
    "                         files=files)\n",
    "    data = json.loads(resp.json())\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network Training\n",
    "(CNN Network Training을 실행한다.)<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trainning ..................................................']\n",
      "['Global Step:     15, Training Batch Accuracy:  11.76%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     20, Training Batch Accuracy:  29.41%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     25, Training Batch Accuracy:  29.41%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     30, Training Batch Accuracy:  11.76%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     35, Training Batch Accuracy:  52.94%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     40, Training Batch Accuracy:  64.71%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     45, Training Batch Accuracy:  52.94%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     50, Training Batch Accuracy:  70.59%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     55, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     60, Training Batch Accuracy:  94.12%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     65, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     70, Training Batch Accuracy:  70.59%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     75, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     80, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     85, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     90, Training Batch Accuracy:  82.35%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     95, Training Batch Accuracy:  100.0%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     100, Training Batch Accuracy:  94.12%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     105, Training Batch Accuracy:  88.24%']\n",
      "\n",
      "['Trainning ..................................................']\n",
      "['Global Step:     110, Training Batch Accuracy:  88.24%']\n",
      "\n",
      "         ['   motor', '     dog', '     car', '   glove', 'airplane', '     cat', '    bolt']\n",
      "         ====================================================================================\n",
      "   motor ['       3', '       0', '       0', '       0', '       0', '       0', '       0']\n",
      "     dog ['       0', '       1', '       0', '       0', '       0', '       0', '       0']\n",
      "     car ['       0', '       0', '       3', '       0', '       0', '       0', '       0']\n",
      "   glove ['       0', '       0', '       0', '       3', '       0', '       0', '       0']\n",
      "airplane ['       0', '       0', '       0', '       0', '       2', '       0', '       1']\n",
      "     cat ['       0', '       0', '       0', '       0', '       0', '       1', '       0']\n",
      "    bolt ['       0', '       0', '       0', '       0', '       0', '       0', '       3']\n"
     ]
    }
   ],
   "source": [
    "resp = requests.post('http://' + url + '/api/v1/type/runmanager/state/train/nnid/'+nn_id+'/ver/'+wf_ver_id+'/')\n",
    "data = json.loads(resp.json())\n",
    "\n",
    "for train in data:\n",
    "    if train != None and train != \"\" and train != {} and train != \"status\" and train != \"result\":\n",
    "        try:\n",
    "            for tr in train[\"TrainResult\"]:\n",
    "                print(tr)\n",
    "        except:\n",
    "            maxcnt = 0\n",
    "            line = \"\"\n",
    "            for label in train[\"labels\"]:\n",
    "                if maxcnt<len(label):\n",
    "                    maxcnt = len(label)\n",
    "\n",
    "            for i in range(len(train[\"labels\"])):\n",
    "                for j in range(maxcnt+4):\n",
    "                    line += \"=\"\n",
    "\n",
    "            label_sub = []\n",
    "            for label in train[\"labels\"]:\n",
    "                label = spaceprint(label,maxcnt)\n",
    "                label_sub.append(label)\n",
    "\n",
    "            space = \"\"\n",
    "            for s in range(maxcnt):\n",
    "                space +=\" \"\n",
    "\n",
    "            print(space, label_sub)\n",
    "            print(space, line)\n",
    "            for i in range(len(train[\"labels\"])):\n",
    "                predict_sub = []\n",
    "                for j in range(len(train[\"predicts\"][i])):\n",
    "                    pred = spaceprint(train[\"predicts\"][i][j],maxcnt)\n",
    "\n",
    "                    predict_sub.append(pred)\n",
    "\n",
    "                print(spaceprint(train[\"labels\"][i],maxcnt), predict_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Network Predict\n",
    "(CNN Network Predict를 실행한다.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileName = 2car.jpg\n",
      "['glovemarketabcde', 'dog', 'glove', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[871.95508, 39.54843, -23.13018, -59.26953, -81.88757, -133.88457, -227.80824, -234.73695, -479.1026]\n",
      "\n",
      "FileName = 1bolt.jpg\n",
      "['glovemarketabcde', 'dog', 'car', 'glove', 'motor', 'airplane', 'cat', 'ca    t', 'bolt']\n",
      "[1197.63708, 79.00513, -22.77024, -37.27081, -84.71973, -212.42955, -270.82303, -276.75476, -647.57831]\n",
      "\n",
      "FileName = 1glove.jpg\n",
      "['glovemarketabcde', 'dog', 'glove', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[1340.97681, 62.86176, 31.42587, 16.51012, -68.01265, -233.03719, -318.09222, -321.92133, -755.56445]\n",
      "\n",
      "FileName = 1car.jpg\n",
      "['glovemarketabcde', 'glove', 'dog', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[858.25964, 55.42708, 49.4529, 15.50914, -85.92107, -146.89845, -169.56615, -205.61496, -450.46146]\n",
      "\n",
      "FileName = 1air.jpg\n",
      "['glovemarketabcde', 'dog', 'glove', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[934.37628, 28.74143, 9.06982, 2.1568, -57.88795, -160.3107, -213.49797, -239.80016, -509.6442]\n",
      "\n",
      "FileName = 2air.jpg\n",
      "['glovemarketabcde', 'dog', 'glove', 'car', 'motor', 'cat', 'airplane', 'ca    t', 'bolt']\n",
      "[1054.54016, 61.16315, 41.61069, 24.04425, -61.27586, -202.97794, -221.27348, -251.52972, -570.255]\n",
      "\n",
      "FileName = 1motor.jpg\n",
      "['glovemarketabcde', 'dog', 'glove', 'car', 'motor', 'airplane', 'cat', 'ca    t', 'bolt']\n",
      "[1309.81531, 44.76609, 35.46022, -14.88056, -73.27342, -201.27139, -286.56601, -300.95068, -693.63751]\n",
      "\n",
      "FileName = 2glove.jpg\n",
      "['glovemarketabcde', 'glove', 'dog', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[1321.54797, 77.13045, 71.64733, -31.25426, -68.22038, -217.21715, -267.29871, -269.49908, -752.13147]\n",
      "\n",
      "FileName = 2bolt.jpg\n",
      "['glovemarketabcde', 'glove', 'dog', 'car', 'motor', 'airplane', 'cat', 'ca    t', 'bolt']\n",
      "[1332.18677, 59.24222, 37.07169, 4.04322, -110.51331, -202.46025, -298.79486, -337.35211, -699.13721]\n",
      "\n",
      "FileName = 2motor.jpg\n",
      "['glovemarketabcde', 'glove', 'dog', 'car', 'motor', 'airplane', 'ca    t', 'cat', 'bolt']\n",
      "[665.61914, 39.45262, 30.28382, 14.41998, -60.90076, -120.20945, -144.39865, -181.20142, -382.02628]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = {\n",
    "         'files000001':  open('/home/dev/hoyai/demo/data/airplane/1air.jpg','rb')\n",
    "        ,'files000002':  open('/home/dev/hoyai/demo/data/airplane/2air.jpg','rb')\n",
    "        ,'files000003':  open('/home/dev/hoyai/demo/data/bolt/1bolt.jpg','rb')\n",
    "        ,'files000004':  open('/home/dev/hoyai/demo/data/bolt/2bolt.jpg','rb')\n",
    "        ,'files000005':  open('/home/dev/hoyai/demo/data/car/1car.jpg','rb')\n",
    "        ,'files000006':  open('/home/dev/hoyai/demo/data/car/2car.jpg','rb')\n",
    "        ,'files000007':  open('/home/dev/hoyai/demo/data/glove/1glove.jpg','rb')\n",
    "        ,'files000008':  open('/home/dev/hoyai/demo/data/glove/2glove.jpg','rb')\n",
    "        ,'files000009':  open('/home/dev/hoyai/demo/data/motor/1motor.jpg','rb')\n",
    "        ,'files000010':  open('/home/dev/hoyai/demo/data/motor/2motor.jpg','rb')\n",
    "        }\n",
    "restURL = 'http://' + url + '/api/v1/type/service/state/predict/type/'+network_type+'/nnid/'+nn_id+'/ver/'+wf_ver_id+'/'\n",
    "\n",
    "resp = requests.post(restURL,\n",
    "                     files=files\n",
    "                     )\n",
    "data = json.loads(resp.json())\n",
    "\n",
    "for train in data:\n",
    "    print(\"FileName = \"+train)\n",
    "    print(data[train]['key'])\n",
    "    print(data[train]['val'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}