{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread, imsave \n",
    "import matplotlib.pyplot as plt  \n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define preprocess func\n"
     ]
    }
   ],
   "source": [
    "def change (x) :\n",
    "    dummy = [0.0, 0.0, 0.0]\n",
    "    idx = ['Clear', 'Rain', 'Clouds']\n",
    "    dummy[idx.index(x)] = 1.0\n",
    "    return dummy\n",
    "\n",
    "def to_matrix(data) :\n",
    "    return_arr = []\n",
    "    idxs = ['humidity', 'pressure', 'grnd_level', 'temp_max', 'temp', 'temp_min', 'temp_kf', 'sea_level']\n",
    "    for idx in idxs : \n",
    "        return_arr.append(float(data.get(idx)))\n",
    "    return return_arr \n",
    "\n",
    "print(\"define preprocess func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define data get func\n"
     ]
    }
   ],
   "source": [
    "def get_test_data() :\n",
    "    resp = requests.get('http://openweathermap.org/data/2.5/forecast?q=London,us&mode=json&appid=b1b15e88fa797225412429c1c50c122a1')\n",
    "    data = resp.json()\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    # parse json\n",
    "    data_list = data['list']\n",
    "    for raw in data_list :\n",
    "        x_data.append(raw['main'])\n",
    "        y_data.append(raw['weather'][0]['main'])\n",
    "\n",
    "    # divide train & test\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(x_data, y_data, test_size=0.20, random_state=42)\n",
    "    \n",
    "    # preprocess data\n",
    "    labels_train = list(map(lambda x : change(x), labels_train ))\n",
    "    labels_test = list(map(lambda x : change(x), labels_test ))\n",
    "    data_filter_train = list(map(lambda x : to_matrix(x), data_train ))\n",
    "    data_filter_test = list(map(lambda x : to_matrix(x), data_test ))\n",
    "    \n",
    "    # Print Data \n",
    "    print(\"data_test : {0}\".format(data_filter_test))\n",
    "    print(\"data_train : {0}\".format(len(data_filter_train)))\n",
    "    print(\"labels_train : {0}\".format(len(labels_train)))\n",
    "    print(\"data_test : {0}\".format(len(data_filter_test)))\n",
    "    print(\"labels_test : {0}\".format(len(labels_test)))\n",
    "\n",
    "    return np.array(labels_train), np.array(labels_test), np.array(data_filter_train), np.array(data_filter_test)\n",
    "\n",
    "print(\"define data get func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define cnn graph func\n"
     ]
    }
   ],
   "source": [
    "def create_graph(train=True):\n",
    "\n",
    "    # placeholder is used for feeding data.\n",
    "    x = tf.placeholder(\"float\", shape=[None, 8], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "    y_target = tf.placeholder(\"float\", shape=[None, 3], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
    "\n",
    "    # reshape input data\n",
    "    x_image = tf.reshape(x, [-1,2,4,1], name=\"x_image\")\n",
    "    \n",
    "    # Build a convolutional layer and maxpooling with random initialization\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([2, 2, 1, 32], stddev=0.1), name=\"W_conv1\") # W is [row, col, channel, feature]\n",
    "    b_conv1 = tf.Variable(tf.zeros([32]), name=\"b_conv1\")\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1, name=\"h_conv1\")\n",
    "    h_pool1 = tf.nn.max_pool( h_conv1 , ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name = \"h_pool1\")\n",
    "    \n",
    "    # Build a fully connected layer\n",
    "    h_pool2_flat = tf.reshape(h_pool1, [-1, 1*2*32], name=\"h_pool2_flat\")\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([1*2*32, 256], stddev=0.1), name = 'W_fc1')\n",
    "    b_fc1 = tf.Variable(tf.zeros([256]), name = 'b_fc1')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "    \n",
    "    keep_prob = 1.0\n",
    "    if(train) : \n",
    "        # Dropout Layer\n",
    "        keep_prob = tf.placeholder(\"float\", name=\"keep_prob\")\n",
    "        h_fc1 = tf.nn.dropout(h_fc1, keep_prob, name=\"h_fc1_drop\")\n",
    "    \n",
    "    # Build a fully connected layer with softmax \n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([256, 3], stddev=0.1), name = 'W_fc2')\n",
    "    b_fc2 = tf.Variable(tf.zeros([3]), name = 'b_fc2')\n",
    "    y=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2, name=\"y\")\n",
    "    \n",
    "    # define the Loss function\n",
    "    #cross_entropy = -tf.reduce_sum(y_target*tf.log(y), name = 'cross_entropy')\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_target))\n",
    "    \n",
    "    # define optimization algorithm\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_target, 1))\n",
    "    # correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
    "    # tf.cast() : changes true -> 1 / false -> 0\n",
    "    # tf.reduce_mean() : calculate the mean\n",
    "    \n",
    "    # create summary of parameters\n",
    "    tf.summary.histogram('weights_1', W_conv1)\n",
    "    tf.summary.histogram('y', y)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    merged = tf.summary.merge_all()\n",
    "    summary_writer = tf.summary.FileWriter(\"/tmp/cnn\")\n",
    "    \n",
    "    return accuracy, x, y_target, keep_prob, train_step, merged, y, cross_entropy, summary_writer, W_conv1\n",
    "    \n",
    "print(\"define cnn graph func\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Hidden Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_layer(weight_list) :\n",
    "#     img = imread('/home/ubuntu/imgtest/wizard.png')\n",
    "#     print(type(img))\n",
    "#     test = np.zeros(shape=(10, 10))\n",
    "#     imsave('/home/ubuntu/imgtest/test.png', test)\n",
    "#     test = imread('/home/ubuntu/imgtest/test.png')\n",
    "    \n",
    "    for matrix in weight_list[0] :  \n",
    "        print(plt.imshow(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_test : [[61.0, 1019.24, 1019.24, 22.1, 22.1, 22.1, 0.0, 1035.16], [79.0, 1016.77, 1016.77, 12.04, 12.04, 12.04, 0.0, 1032.94], [81.0, 1016.01, 1016.01, 13.68, 13.68, 13.68, 0.0, 1031.95], [88.0, 1018.84, 1018.84, 12.11, 12.11, 12.11, 0.0, 1035.03], [56.0, 1014.32, 1014.32, 22.7, 22.7, 22.7, 0.0, 1030.25], [57.0, 1020.96, 1020.96, 23.43, 23.43, 23.43, 0.0, 1036.87], [87.0, 1015.64, 1015.64, 10.35, 10.35, 10.35, 0.0, 1031.87], [56.0, 1019.72, 1019.72, 23.73, 23.73, 23.73, 0.0, 1035.68]]\n",
      "data_train : 29\n",
      "labels_train : 29\n",
      "data_test : 8\n",
      "labels_test : 8\n",
      "WARNING:tensorflow:From <ipython-input-171-63d68b5038f2>:12: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "step 0, training accuracy: 0.138\n",
      "summary for tensorboard written\n",
      "step 10, training accuracy: 0.138\n",
      "summary for tensorboard written\n",
      "step 20, training accuracy: 0.138\n",
      "summary for tensorboard written\n",
      "step 30, training accuracy: 0.138\n",
      "summary for tensorboard written\n",
      "step 40, training accuracy: 0.138\n",
      "summary for tensorboard written\n",
      "step 50, training accuracy: 0.414\n",
      "summary for tensorboard written\n",
      "step 60, training accuracy: 0.690\n",
      "summary for tensorboard written\n",
      "step 70, training accuracy: 0.690\n",
      "summary for tensorboard written\n",
      "step 80, training accuracy: 0.690\n",
      "summary for tensorboard written\n",
      "step 90, training accuracy: 0.690\n",
      "summary for tensorboard written\n",
      "test accuracy: 1\n",
      "AxesImage(54,36;334.8x223.2)\n",
      "AxesImage(54,36;334.8x223.2)\n",
      "model saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAA7CAYAAAAXZtIzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f508c0d4828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run() : \n",
    "    try : \n",
    "        # get Data \n",
    "        labels_train, labels_test, data_filter_train, data_filter_test = get_test_data()\n",
    "        # reset Graph\n",
    "        tf.reset_default_graph()   \n",
    "        # Create Session\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))  \n",
    "        # create graph\n",
    "        accuracy, x, y_target, keep_prob, train_step, merged, y, cross_entropy, summary_writer, W_conv1 = create_graph(train=True)\n",
    "        # set saver\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        # initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        # training the MLP\n",
    "        for i in range(100): \n",
    "            sess.run(train_step, feed_dict={x: data_filter_train, y_target: labels_train, keep_prob: 0.5})\n",
    "            if i%10 == 0:\n",
    "                train_accuracy = sess.run(accuracy, feed_dict={x:data_filter_train, y_target: labels_train, keep_prob: 1})\n",
    "                print (\"step %d, training accuracy: %.3f\"%(i, train_accuracy))\n",
    "                \n",
    "                # calculate the summary and write.\n",
    "                summary = sess.run(merged, feed_dict={x:data_filter_train, y_target: labels_train, keep_prob: 1})\n",
    "                summary_writer.add_summary(summary , i)\n",
    "                print(\"summary for tensorboard written\")\n",
    "                \n",
    "        # for given x, y_target data set\n",
    "        print  (\"test accuracy: %g\"% sess.run(accuracy, feed_dict={x:data_filter_test, y_target: labels_test, keep_prob: 1}))\n",
    "        \n",
    "        # show weight matrix as image \n",
    "        weight_vectors = sess.run(W_conv1, feed_dict={x: data_filter_train, y_target: labels_train, keep_prob: 1.0})\n",
    "        show_layer(weight_vectors)\n",
    "        \n",
    "        # Save Model\n",
    "        path = './model/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(\"path created\")\n",
    "        saver.save(sess, path)\n",
    "        print(\"model saved\")\n",
    "    except Exception as e : \n",
    "        raise Exception (\"error on training: {0}\".format(e))\n",
    "    finally :\n",
    "        sess.close()\n",
    "\n",
    "# run stuff\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/\n",
      "model restored\n",
      "input data : [63.0, 1017.55, 1017.55, 24.05, 24.05, 24.05, 0.0, 1033.55]\n",
      "result : [array([[ 1.,  0.,  0.]], dtype=float32)]\n",
      "result : 0\n"
     ]
    }
   ],
   "source": [
    "def predict(test_data) : \n",
    "    try : \n",
    "        # reset Graph\n",
    "        tf.reset_default_graph()   \n",
    "        # Create Session\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))  \n",
    "        # create graph\n",
    "        _, x, _, _, _, _, y, _, _, _ = create_graph(train=False)\n",
    "        \n",
    "        # initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # set saver\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # Restore Model\n",
    "        path = './model/'\n",
    "        if os.path.exists(path):\n",
    "            saver.restore(sess, path)\n",
    "            print(\"model restored\")\n",
    "\n",
    "        # training the MLP\n",
    "        print(\"input data : {0}\".format(test_data))\n",
    "        y = sess.run([y], feed_dict={x: np.array([test_data])})\n",
    "        print(\"result : {0}\".format(y))\n",
    "        print(\"result : {0}\".format(np.argmax(y)))\n",
    "        \n",
    "    except Exception as e : \n",
    "        raise Exception (\"error on training: {0}\".format(e))\n",
    "    finally :\n",
    "        sess.close()\n",
    "\n",
    "# run stuff\n",
    "predict([63.0, 1017.55, 1017.55, 24.05, 24.05, 24.05, 0.0, 1033.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
